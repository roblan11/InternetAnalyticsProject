{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks: structure, evolution & processes\n",
    "**Internet Analytics - Lab 2**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *K*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Robin Lang*\n",
    "* *Kim Lan Phan Hoang*\n",
    "* *Julien Harbulot*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 4 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import epidemics_helper\n",
    "import json\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2.4 PageRank\n",
    "\n",
    "### 2.4.1 Random Surfer Model\n",
    "\n",
    "#### Exercise 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# open the files and store them as graphs\n",
    "absorbing_file = open(\"../data/absorbing.graph\", \"rb\")\n",
    "absorbing_graph = nx.read_adjlist(absorbing_file, create_using=nx.DiGraph())\n",
    "\n",
    "components_file = open(\"../data/components.graph\", \"rb\")\n",
    "components_graph = nx.read_adjlist(components_file, create_using=nx.DiGraph())\n",
    "\n",
    "wikipedia_file = open(\"../data/wikipedia.graph\", \"rb\")\n",
    "wikipedia_graph = nx.read_adjlist(wikipedia_file, create_using=nx.DiGraph())\n",
    "\n",
    "G_n1 = nx.read_edgelist('../data/network1.csv', delimiter=',', nodetype=int, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run the random surfer algorithm of graph G for N steps\n",
    "def random_surfer(G, N = 5):\n",
    "    nodes = nx.nodes(G)\n",
    "    num_nodes = len(nodes)\n",
    "    prob = np.zeros(num_nodes)\n",
    "    first_node = random.choice(nodes)\n",
    "    \n",
    "    succ = G.successors(first_node)\n",
    "    \n",
    "    # first node has no successors\n",
    "    if len(succ) == 0:\n",
    "        prob[int(first_node)] = 1\n",
    "        return prob\n",
    "    \n",
    "    # construct probability vector\n",
    "    for n in succ:\n",
    "        prob[int(n)] = 1/len(succ)\n",
    "        \n",
    "    # itherate over the number of iterations\n",
    "    for i in range(N-1):\n",
    "        prob_next = np.zeros(num_nodes)\n",
    "        \n",
    "        # iterate over all nodes\n",
    "        for j in nodes:\n",
    "            \n",
    "            # if the current node has probability 0 at this step, do nothing\n",
    "            if prob[int(j)] > 0:\n",
    "                succ = G.successors(j)\n",
    "                \n",
    "                # if the current node has successor(s), compute the corresponding probabilities\n",
    "                if len(succ) > 0:\n",
    "                    for n in succ:\n",
    "                        prob_next[int(n)] += prob[int(j)] / len(succ)\n",
    "                        \n",
    "                # otherwise the current node is absorbing and keeps its probability\n",
    "                else:\n",
    "                    prob_next[int(j)] += prob[int(j)]\n",
    "                    \n",
    "        # update the probability at each iteration\n",
    "        prob = prob_next\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03703704,  0.92592593,  0.03703704,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_surfer(absorbing_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the obtained matrix is either [ 0.,  1.,  0.,  0.,  0.] or is very close to that.\n",
    "\n",
    "This shows that the second node is an absorbing state, which means that it has no outgoing links. Therefore, whenever we reach (or even start at) this node, we cannot pass onto any other node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5,  0. ,  0.5,  0. ,  0. ,  0. ,  0. ,  0. ])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_surfer(components_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run an improvement for the random surfer algorithm of graph G for N steps\n",
    "# in this improvement, every time an absorbing node is reached, jump to a random node\n",
    "def method1(G, N = 5):\n",
    "    nodes = nx.nodes(G)\n",
    "    num_nodes = len(nodes)\n",
    "    prob = np.zeros(num_nodes)\n",
    "    first_node = random.choice(nodes)\n",
    "    \n",
    "    succ = G.successors(first_node)\n",
    "    \n",
    "    # if the initial node is absorbing\n",
    "    if len(succ) == 0:\n",
    "        prob[int(first_node)] = 1\n",
    "    \n",
    "    # initialize the table of probabilities\n",
    "    for n in succ:\n",
    "        prob[int(n)] = 1/len(succ)\n",
    "    \n",
    "    # itherate over the number of iterations\n",
    "    for i in range(N-1):\n",
    "        prob_next = np.zeros(num_nodes)\n",
    "        \n",
    "        # iterate over all nodes\n",
    "        for j in nodes:\n",
    "            \n",
    "            # if the current node has probability 0 at this step, do nothing\n",
    "            if prob[int(j)] > 0:\n",
    "                succ = G.successors(j)\n",
    "                \n",
    "                # if the current node has successor(s), compute the corresponding probabilities\n",
    "                if len(succ) > 0:\n",
    "                    for n in succ:\n",
    "                        prob_next[int(n)] += prob[int(j)] / len(succ)\n",
    "                \n",
    "                # otherwise the current node is absorbing, jump to a random node (and transfer the probability)\n",
    "                else:\n",
    "                    prob_next[int(random.choice(nodes))] += prob[int(j)]\n",
    "                    \n",
    "        # update the probability at each iteration\n",
    "        prob = prob_next\n",
    "        \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12156056,  0.38807749,  0.21709773,  0.02922413,  0.24404009])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method1(absorbing_graph, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.28571572,\n",
       "        0.14285675,  0.28571314,  0.28571438])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method1(components_graph, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def method2(G, N = 5, damp = 0.15):\n",
    "    nodes = nx.nodes(G)\n",
    "    num_nodes = len(nodes)\n",
    "    prob = np.zeros(num_nodes)\n",
    "    first_node = random.choice(nodes)\n",
    "    \n",
    "    succ = G.successors(first_node)\n",
    "    \n",
    "    if len(succ) == 0:\n",
    "        prob[int(first_node)] = 1\n",
    "        return prob\n",
    "    \n",
    "    for n in succ:\n",
    "        prob[int(n)] = 1/len(succ)\n",
    "        \n",
    "    for i in range(N-1):\n",
    "        if np.random.choice([True, False], p=[damp, 1-damp]):\n",
    "            print(\"1-2-SWITCH\")\n",
    "        prob_next = np.zeros(num_nodes)\n",
    "        for j in nodes:\n",
    "            if prob[int(j)] > 0:\n",
    "                succ = G.successors(j)\n",
    "                if len(succ) > 0:\n",
    "                    for n in succ:\n",
    "                        prob_next[int(n)] += prob[int(j)] / len(succ)\n",
    "                else:\n",
    "                    prob_next[int(j)] += prob[int(j)]\n",
    "        prob = prob_next\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method2(absorbing_graph, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.2 Power Iteration Method\n",
    "\n",
    "#### Exercise 2.14: Power Iteration method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the w vector, which initialize the position of dangling node to 1\n",
    "def danglingNodes(G):\n",
    "    nbNodes = nx.number_of_nodes(G)\n",
    "    w = np.zeros([nbNodes,nbNodes]);\n",
    "    \n",
    "    for i in G.nodes_iter():\n",
    "        outDegreeCurrent = G.out_degree(i)\n",
    "        if(outDegreeCurrent == 0):\n",
    "            for j in G.nodes_iter():\n",
    "                w[int(i),int(j)] = 1\n",
    "    return w\n",
    "\n",
    "\n",
    "# create markov chain matrix, where position ij is the probability to go from i to j\n",
    "def markovMatrix(G):\n",
    "    nbNodes = G.number_of_nodes()\n",
    "    H = np.zeros([nbNodes,nbNodes])\n",
    "    \n",
    "    for n in G.nodes_iter():\n",
    "        outDegreeCurrent = G.out_degree(n)\n",
    "        for i in G.neighbors(n):\n",
    "            H[int(n),int(i)] = 1/outDegreeCurrent\n",
    "            \n",
    "    return H\n",
    "    \n",
    "\n",
    "# main power iteration\n",
    "def powerIteration(G, theta):\n",
    "    \n",
    "    N = G.number_of_nodes()\n",
    "    \n",
    "    w = danglingNodes(G)\n",
    "    H = markovMatrix(G)\n",
    "    \n",
    "    # initial vector pi_0\n",
    "    matrix = np.empty(N)\n",
    "    matrix.fill(1/N)\n",
    "    \n",
    "    # apply formula \n",
    "    H_hat = np.add(H, w/N)\n",
    "    Google = (theta*H_hat) + ((1-theta)/N)\n",
    "    \n",
    "    count = 0\n",
    "    while(count != 30):\n",
    "        \n",
    "        newMatrix = matrix @ Google\n",
    "        \n",
    "        # check for convergence\n",
    "        if(np.array_equal(matrix, newMatrix)):\n",
    "            count += 1\n",
    "        else :\n",
    "            count = 0\n",
    "            \n",
    "        matrix = newMatrix\n",
    "    \n",
    "    return matrix\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 page ids : [2214 1651 1661 1665 1673 1675 1676 1684 1692 1693]\n"
     ]
    }
   ],
   "source": [
    "power_it = powerIteration(wikipedia_graph,0.8)\n",
    "#obtain the 10 best ids\n",
    "best10 = power_it.argsort()[:10]\n",
    "print(\"Top 10 page ids :\",best10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the corresponding book titles :\n",
    "\n",
    "2214 - Godspell<br>\n",
    "1651 - Dr. Seuss<br>\n",
    "1661 - Dundee United F.C.<br>\n",
    "1665 - Dunstable and Whipsnade Downs<br>\n",
    "1673 - Dysphania ambrosioides<br>\n",
    "1675 - â‚¬2 commemorative coins<br>\n",
    "1676 - e (mathematical constant)<br>\n",
    "1684 - Earwax<br>\n",
    "1692 - Eastern Roman Empire<br>\n",
    "1693 - East Flemish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.4.3 Gaming the system *(Bonus)*\n",
    "\n",
    "#### Exercise 2.15 *(Bonus)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of page History of matemathics: 9.97890687703e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"Score of page History of matemathics:\",power_it[2463])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The idea is to add edges between best ranked pages to our page History of matemathics. That is, our page will be more visited and thus have a better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end we obtain a score of  0.000953734890423 when adding 300 new edges\n"
     ]
    }
   ],
   "source": [
    "wikipedia_file1 = open(\"../data/wikipedia.graph\", \"rb\")\n",
    "G = nx.read_adjlist(wikipedia_file1, create_using=nx.DiGraph())\n",
    "\n",
    "# add new edges\n",
    "nbEdges = 300\n",
    "edgesToDelete = power_it.argsort()[:nbEdges]\n",
    "for i in edgesToDelete:\n",
    "    toNode = i\n",
    "    G.add_edge(str(toNode),'2463')\n",
    "\n",
    "print(\"At the end we obtain a score of \",powerIteration(G, 0.8)[2463], \"when we add\",nbEdges, \"new edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
