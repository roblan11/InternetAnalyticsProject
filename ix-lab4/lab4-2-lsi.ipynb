{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** K\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Kim Lan Phan Hoang\n",
    "* Robin Lang\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the arrays from the first part\n",
    "X = np.load(\"data/TFIDF.npy\")\n",
    "X = X.T\n",
    "words = np.load(\"data/words.npy\")\n",
    "courses = np.load(\"data/courses.npy\")\n",
    "\n",
    "# initialize the array sizes for SVD\n",
    "M = len(words)\n",
    "N = len(courses)\n",
    "K = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Apply SVD with K = 300 to your term-document matrix X from the previous exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the SVD of X\n",
    "U, S, VT = svds(X, k=K)\n",
    "V = VT.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the rows and columns of U and V, and the values of S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The rows of U are the left singular eigenvectors. Each row is the topic distribution of a term.\n",
    "\n",
    "The columns of V are the right singular eigenvectors. Each row is the topic distribution of a course description.\n",
    "\n",
    "The values in S are the eigenvalues, ordered from smallest to largest. This gives an \"importance\" to each topic. So a high value in S for a topic means that topic is more frequent within the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the top-20 eigenvalues of X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LARGEST 20 EIGENVALUES:\n",
      "[ 61.4911109   41.11869589  38.06116804  36.89655454  35.64803951\n",
      "  34.57357261  33.17108239  32.71968738  32.20601846  31.4253953\n",
      "  31.10123689  30.36687001  29.97372375  29.73694418  28.73211126\n",
      "  28.65421312  28.46731951  28.27977773  28.22180541  27.95464965]\n"
     ]
    }
   ],
   "source": [
    "print(\"LARGEST 20 EIGENVALUES:\")\n",
    "print(S[:-21:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "### Extract the topics from the term-document matrix X using the low-rank approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the topics, containing their eigenvalue,\n",
    "# as well as the lists containing the weights of\n",
    "# the terms and courses within this topic respectively\n",
    "topics = []\n",
    "\n",
    "# note: this array is computet inversly over S,\n",
    "# therefore the eigenvalues will be sorted\n",
    "# from largest to smallest\n",
    "for i in range(K-1, 0, -1):\n",
    "    topics.append([S[i], U.T[i], VT[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the top-10 topics as a combination of terms and a combination of documents.\n",
    "\n",
    "For this, we will print the top 10 terms and documents respectively of the top-10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: 1 ( eigenvalue: 61.4911108973 )\n",
      "  top10 terms:\n",
      "    0.108270211004 : project\n",
      "    0.0816817895981 : data\n",
      "    0.0756358641883 : report\n",
      "    0.0755159062971 : materials\n",
      "    0.0726962641445 : research\n",
      "    0.0726730141339 : work\n",
      "    0.0705602992579 : engineer\n",
      "    0.0701417892484 : basic\n",
      "    0.0681158492668 : study\n",
      "    0.0676815304476 : theory\n",
      "  top10 courses:\n",
      "    0.110097689162 : ChE-437\n",
      "    0.105206639795 : CH-413\n",
      "    0.10155141235 : PENS-210\n",
      "    0.0980084587656 : BIO-487\n",
      "    0.0850466515802 : PHYS-106(en)\n",
      "    0.0806883548355 : MATH-468\n",
      "    0.0801779660628 : ChE-311\n",
      "    0.0788014289508 : BIO-105\n",
      "    0.0780009478045 : ME-475\n",
      "    0.0779429329881 : CH-492\n",
      "\n",
      "topic: 2 ( eigenvalue: 41.1186958882 )\n",
      "  top10 terms:\n",
      "    0.0500541127238 : financial\n",
      "    0.0439373949129 : price\n",
      "    0.0412431684583 : finance\n",
      "    0.0380250945786 : linear\n",
      "    0.0348625575018 : numerical\n",
      "    0.0337247795024 : probability\n",
      "    0.0332250663039 : stochastic\n",
      "    0.0329423109591 : algorithms\n",
      "    0.0312462318759 : optimization\n",
      "    0.0308988798617 : market\n",
      "  top10 courses:\n",
      "    0.0675201020444 : MGT-482\n",
      "    0.0569212153697 : FIN-401\n",
      "    0.0512010423164 : FIN-402\n",
      "    0.0477741962156 : FIN-404\n",
      "    0.0426836065424 : FIN-606\n",
      "    0.0400843683843 : MATH-468\n",
      "    0.0399923572705 : MATH-472\n",
      "    0.0399258504739 : MATH-461\n",
      "    0.0398848640723 : FIN-407\n",
      "    0.0377470770597 : FIN-601\n",
      "\n",
      "topic: 3 ( eigenvalue: 38.0611680444 )\n",
      "  top10 terms:\n",
      "    0.106730387002 : financial\n",
      "    0.0966803732202 : project\n",
      "    0.091928813975 : finance\n",
      "    0.0856938651662 : price\n",
      "    0.0719275107065 : data\n",
      "    0.0698945736112 : market\n",
      "    0.0697071786073 : edms\n",
      "    0.0692962703835 : doctoral students\n",
      "    0.0677053077485 : risk\n",
      "    0.0645081854468 : corporate\n",
      "  top10 courses:\n",
      "    0.150582221333 : MGT-482\n",
      "    0.135747786852 : FIN-401\n",
      "    0.0933332670041 : FIN-601\n",
      "    0.0892536044903 : PENS-210\n",
      "    0.0854377904687 : MGT-414\n",
      "    0.0821222702367 : BIO-676\n",
      "    0.0813255290304 : FIN-404\n",
      "    0.0807169739816 : FIN-402\n",
      "    0.0756164985809 : FIN-405\n",
      "    0.0730100873483 : BIOENG-489\n",
      "\n",
      "topic: 4 ( eigenvalue: 36.8965545398 )\n",
      "  top10 terms:\n",
      "    0.128087125299 : stochastic\n",
      "    0.118643682486 : linear\n",
      "    0.105563428294 : probability\n",
      "    0.104367800757 : financial\n",
      "    0.103154037769 : price\n",
      "    0.0976205503991 : numerical\n",
      "    0.0914713342195 : algorithms\n",
      "    0.0893401447213 : equations\n",
      "    0.0836947474296 : finance\n",
      "    0.0778824251533 : optimization\n",
      "  top10 courses:\n",
      "    0.132453348676 : FIN-402\n",
      "    0.131844655535 : CS-435\n",
      "    0.12754761891 : FIN-606\n",
      "    0.112122155762 : MATH-472\n",
      "    0.112105866112 : FIN-404\n",
      "    0.111214899128 : MATH-457\n",
      "    0.103672721161 : MATH-468\n",
      "    0.102822184114 : FIN-408\n",
      "    0.101012011066 : PHYS-403\n",
      "    0.0984482139248 : MATH-470\n",
      "\n",
      "topic: 5 ( eigenvalue: 35.6480395106 )\n",
      "  top10 terms:\n",
      "    0.0698119803802 : energy\n",
      "    0.0694137701675 : heat\n",
      "    0.064892159413 : kinetics\n",
      "    0.0541399667309 : transport\n",
      "    0.0532242546345 : cell\n",
      "    0.0519557980049 : bioprocess\n",
      "    0.0519220829465 : chemistry\n",
      "    0.0513343279753 : fluid\n",
      "    0.0505750972215 : molecular\n",
      "    0.0503962918534 : properties\n",
      "  top10 courses:\n",
      "    0.143066640875 : ChE-437\n",
      "    0.125181505742 : ChE-311\n",
      "    0.0894383425496 : PHYS-106(en)\n",
      "    0.0823915866587 : CH-492\n",
      "    0.0777527612289 : ENV-715\n",
      "    0.0681925305756 : CH-447\n",
      "    0.0634197497978 : ChE-403\n",
      "    0.0623873552183 : MICRO-566\n",
      "    0.0602891657395 : ME-551\n",
      "    0.0602669056204 : CH-311\n",
      "\n",
      "topic: 6 ( eigenvalue: 34.5735726083 )\n",
      "  top10 terms:\n",
      "    0.190858390777 : financial\n",
      "    0.162241210614 : finance\n",
      "    0.158495840277 : price\n",
      "    0.141769310602 : risk\n",
      "    0.122897124633 : corporate finance\n",
      "    0.119805147624 : corporate\n",
      "    0.119700530644 : market\n",
      "    0.115824837807 : valuation\n",
      "    0.110988016814 : asset\n",
      "    0.098255090962 : derivatives\n",
      "  top10 courses:\n",
      "    0.273463915067 : MGT-482\n",
      "    0.262382476876 : FIN-401\n",
      "    0.183513075696 : ChE-437\n",
      "    0.181862727218 : FIN-601\n",
      "    0.169053144145 : FIN-609\n",
      "    0.153398977288 : FIN-405\n",
      "    0.152106698868 : ChE-311\n",
      "    0.13768979447 : FIN-404\n",
      "    0.120188784386 : FIN-402\n",
      "    0.117325344894 : CH-413\n",
      "\n",
      "topic: 7 ( eigenvalue: 33.1710823943 )\n",
      "  top10 terms:\n",
      "    0.130903331544 : drug\n",
      "    0.106516451147 : molecular\n",
      "    0.097321484372 : protein\n",
      "    0.0864758589957 : dna\n",
      "    0.082522601256 : pharmacology\n",
      "    0.0706904067211 : biophysical\n",
      "    0.0696582308122 : scientific\n",
      "    0.0689146950977 : literature\n",
      "    0.0686659014941 : disease\n",
      "    0.0683997929591 : medicine\n",
      "  top10 courses:\n",
      "    0.268037763209 : BIO-487\n",
      "    0.219823042268 : CH-413\n",
      "    0.142164351636 : CH-311\n",
      "    0.126132934906 : BIO-502\n",
      "    0.125091122123 : BIO-503\n",
      "    0.124517286831 : BIOENG-489\n",
      "    0.121580064928 : BIO-501\n",
      "    0.1156797543 : BIO-506\n",
      "    0.112589189589 : BIO-507\n",
      "    0.112449992405 : BIO-504\n",
      "\n",
      "topic: 8 ( eigenvalue: 32.7196873775 )\n",
      "  top10 terms:\n",
      "    0.142099381111 : drug\n",
      "    0.119105701131 : circuit\n",
      "    0.11828195349 : optical\n",
      "    0.0906190787884 : pharmacology\n",
      "    0.0901316055198 : sensors\n",
      "    0.0830779978627 : signal\n",
      "    0.0828836494632 : devices\n",
      "    0.0807152019184 : disease\n",
      "    0.0789168449527 : nanobiotechnological\n",
      "    0.0757136319381 : digital\n",
      "  top10 courses:\n",
      "    0.293149252662 : BIO-487\n",
      "    0.265158146671 : CH-413\n",
      "    0.115564355377 : BIO-494\n",
      "    0.105338770275 : BIOENG-445\n",
      "    0.0846387428955 : CH-448\n",
      "    0.0813418703041 : EE-613\n",
      "    0.0804972247005 : EE-606\n",
      "    0.0799174169516 : MICRO-611\n",
      "    0.0790278162066 : MICRO-432\n",
      "    0.0787783019575 : EE-535\n",
      "\n",
      "topic: 9 ( eigenvalue: 32.2060184601 )\n",
      "  top10 terms:\n",
      "    0.122282541569 : bioprocess\n",
      "    0.115090796115 : studio\n",
      "    0.11257377689 : architectural\n",
      "    0.0918770367891 : downstream\n",
      "    0.0895116824395 : kinetics\n",
      "    0.0888950540747 : urban\n",
      "    0.0821953670987 : drug\n",
      "    0.0761474385294 : pharmacology\n",
      "    0.0736102323285 : adsorption\n",
      "    0.0702385756444 : precipitation\n",
      "  top10 courses:\n",
      "    0.31608118452 : ChE-437\n",
      "    0.260719932098 : ChE-311\n",
      "    0.24760707938 : BIO-487\n",
      "    0.210267385979 : AR-401(y)\n",
      "    0.208053470363 : AR-402(y)\n",
      "    0.0939572296783 : MSE-636(a)\n",
      "    0.0939572296783 : MSE-636(b)\n",
      "    0.093577993953 : AR-402(b)\n",
      "    0.0926124918518 : BIO-494\n",
      "    0.0905997582738 : AR-401(b)\n",
      "\n",
      "topic: 10 ( eigenvalue: 31.4253953036 )\n",
      "  top10 terms:\n",
      "    0.163977907935 : circuit\n",
      "    0.126138173418 : bioprocess\n",
      "    0.0931919566056 : downstream\n",
      "    0.0891609371358 : analog\n",
      "    0.083005912337 : kinetics\n",
      "    0.078734390571 : signal\n",
      "    0.0778353756392 : integrate\n",
      "    0.076289337537 : adsorption\n",
      "    0.0686623119969 : bioreactors\n",
      "    0.0685132656056 : dsp\n",
      "  top10 courses:\n",
      "    0.318308890238 : ChE-437\n",
      "    0.252292662297 : ChE-311\n",
      "    0.157900010536 : PHYS-458\n",
      "    0.129178210316 : PHYS-459\n",
      "    0.126475019246 : EE-429\n",
      "    0.106517551425 : BIO-487\n",
      "    0.0893295429888 : EE-421\n",
      "    0.0887516905123 : EE-434\n",
      "    0.0852788547764 : MICRO-704\n",
      "    0.083342570027 : MICRO-432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the first 10 terms will be the top 10\n",
    "for i in range(10):\n",
    "    curr = topics[i]\n",
    "    \n",
    "    # title of each topic with it eigenvalue\n",
    "    print(\"topic:\", i+1, \"( eigenvalue:\", curr[0], \")\")\n",
    "    \n",
    "    # print the top 10 terms within that topic\n",
    "    print(\"  top10 terms:\")\n",
    "    for t in np.argsort(-curr[1])[:10]:\n",
    "        print(\"   \", curr[1][t], \":\", words[t])\n",
    "    \n",
    "    # print the top 10 courses within that topic\n",
    "    print(\"  top10 courses:\")\n",
    "    for t in np.argsort(-curr[2])[:10]:\n",
    "        print(\"   \", curr[2][t], \":\", courses[t])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give a label to each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**topic 1: semester project** <br>\n",
    "project, data, report, materials, research, work, engineer, basic, study, theory\n",
    "\n",
    "**topic 2: finance analysis** <br>\n",
    "financial, price, finance, linear, numerical, probability, stochastic, algorithms, optimization, market\n",
    "\n",
    "**topic 3: financial market** <br>\n",
    "financial, project, finance, price, data, market, edms, doctoral students, risk, corporate\n",
    "\n",
    "**topic 4: probabilistic finance analysis** <br>\n",
    "stochastic, linear, probability, financial, price, numerical, algorithms, equations, finance, optimization\n",
    "\n",
    "**topic 5: body physics** <br>\n",
    "energy, heat, kinetics, transport, cell, bioprocess, chemistry, fluid, molecular, properties\n",
    "\n",
    "**topic 6: corproate finances** <br>\n",
    "financial, finance, price, risk, corporate finance, corporate, market, valuation, asset, derivatives\n",
    "\n",
    "**topic 7: pharmacology** <br>\n",
    "drug, molecular, protein, dna, pharmacology, biophysical, scientific, literature, disease, medicine\n",
    "\n",
    "**topic 8: sensorial pharmacology** <br>\n",
    "drug, circuit, optical, pharmacology, sensors, signal, devices, disease, nanobiotechnological, digital\n",
    "\n",
    "**topic 9: biokinetics** <br>\n",
    "bioprocess, studio, architectural, downstream, kinetics, urban, drug, pharmacology, adsorption, precipitation\n",
    "\n",
    "**topic 10: reactionary bioprocesses** <br>\n",
    "circuit, bioprocess, downstream, analog, kinetics, signal, integrate, adsorption, bioreactors, dsp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# document similarity given the document's and term's index\n",
    "def docsim(t, d):\n",
    "    return ( np.dot(U[t], S*V[d]) ) / ( np.linalg.norm(U[t]) * np.linalg.norm(S*V[d]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Implement a search function using LSI concept-space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the dictionaries to return the indexes\n",
    "# of terms / courses from their name\n",
    "words_dict = np.load(\"data/words_dict.npy\").item()\n",
    "courses_dict = np.load(\"data/courses_dict.npy\").item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for \"facebook\" in both VSM and LSI. How does it compare? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As before, the term \"facebook\" does not exist in the filtered list of terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for \"markov chains\" and compare with the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the docsim of each course with the term 'markov chain'\n",
    "markov_index = words_dict['markov chain']\n",
    "markov_sim = []\n",
    "\n",
    "for i in range(N):\n",
    "    markov_sim.append(docsim(markov_index, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 10 COURSES FOR 'MARKOV CHAIN'\n",
      "  0.857005393917 : MATH-332\n",
      "  0.767029694205 : COM-516\n",
      "  0.725089702301 : MGT-484\n",
      "  0.304445132341 : MATH-600\n",
      "  0.268045333444 : COM-512\n",
      "  0.209648482257 : FIN-408\n",
      "  0.173026424099 : COM-308\n",
      "  0.148197356075 : COM-417\n",
      "  0.130716391711 : FIN-409\n",
      "  0.119442811712 : EE-554\n"
     ]
    }
   ],
   "source": [
    "# find and print the best 10 similarity scores\n",
    "LSI_markov_top10 = np.argsort(-np.array(markov_sim))[:10]\n",
    "top_markov_names = []\n",
    "\n",
    "print(\"TOP 10 COURSES FOR 'MARKOV CHAIN'\")\n",
    "for i in LSI_markov_top10:\n",
    "    top_markov_names.append([i, courses[i]])\n",
    "    print(\" \", markov_sim[i], \":\", courses[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|         | top 1    | top 2   | top 3   | top 4    | top 5   |\n",
    "|--------:|:--------:|:-------:|:-------:|:--------:|:-------:|\n",
    "| **VSM** | MATH-332 | COM-516 | MGT-484 | FIN-408  | COM-308 |\n",
    "| **LSI** | MATH-332 | COM-516 | MGT-484 | MATH-600 | COM-512 |\n",
    "\n",
    "The first three courses are identical, the last two courses are different, but they are still from the same sections (namely mathematics \"MATH\" and communication systems \"COM\"). However, the top 4-5 courses from VSM are the top 6-7 courses in LSI, so they are still similarly placed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Find the classes that are the most similar to Internet Analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# index of the internet analytics course\n",
    "ia_index = courses_dict['COM-308']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write down the equation to efficiently compute the similarity between documents.\n",
    "\n",
    "Since the topic distribution of a document is entirely stored in V, we only have to compare the right singular vectors of X, or the rows of V.\n",
    "\n",
    "Other than that, cosine similarity can be used between the vectors, as it is very efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# similarity between two courses given their indexes\n",
    "def sim(i, j):\n",
    "    di = V[i]\n",
    "    dj = V[j]\n",
    "    return np.dot(di, dj) / ( np.linalg.norm(di) * np.linalg.norm(dj) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the top 5 classes most similar to COM-308."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute the similarity scores between\n",
    "# the courses and 'COM-308'\n",
    "ia_sim = []\n",
    "\n",
    "for v in range(len(V)):\n",
    "    if v == ia_index:\n",
    "        # set the similarity of COM-308 with itself\n",
    "        # to -1, to avoid it being one of the best\n",
    "        ia_sim.append(-1)\n",
    "    else:\n",
    "        ia_sim.append(sim(v, ia_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 5 COURSES SIMILAR TO 'COM-308'\n",
      "  0.501552676399 : CS-423\n",
      "  0.394303998676 : EE-558\n",
      "  0.353265127305 : CS-401\n",
      "  0.332978132722 : EE-727\n",
      "  0.305013338653 : FIN-525\n"
     ]
    }
   ],
   "source": [
    "# compute the best 5 similarity scores\n",
    "ia_sim_top5 = np.argsort(-np.array(ia_sim))[:5]\n",
    "\n",
    "print(\"TOP 5 COURSES SIMILAR TO 'COM-308'\")\n",
    "for i in ia_sim_top5:\n",
    "    print(\" \", ia_sim[i], \":\", courses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
