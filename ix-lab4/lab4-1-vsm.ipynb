{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** K\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Kim Lan Phan Hoang\n",
    "* Robin Lang\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')\n",
    "punctuation = '.?!,;:-–()[]{}\"/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pre-process the corpus to create bag-of-words representations of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN = 10\n",
    "MAX = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "courses_proc = {}\n",
    "words = {}\n",
    "cids = []\n",
    "\n",
    "for c in courses:\n",
    "    cid = c['courseId']\n",
    "    cids.append(cid)\n",
    "    \n",
    "    # transfer all to lowercase, remove punctuation\n",
    "    desc = c['description'].lower().translate(str.maketrans('', '', punctuation))\n",
    "    # remove stopwords\n",
    "    desc_proc = [word for word in desc.split() if word not in stopwords]\n",
    "    \n",
    "    # create a dict of all words\n",
    "    for w in desc_proc:\n",
    "        if w in words:\n",
    "            words[w] += 1\n",
    "        else:\n",
    "            words[w] = 1\n",
    "    \n",
    "    # not needed ?\n",
    "    #name = c['name']\n",
    "    #courses_proc[cid] = desc_proc\n",
    "    \n",
    "    if cid in courses_proc:\n",
    "        # some courseIds appear multiple times\n",
    "        # for those, we decided to append the desctiptions to each other\n",
    "        courses_proc[cid].extend(desc_proc)\n",
    "    else:\n",
    "        courses_proc[cid] = desc_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_filtered = []\n",
    "\n",
    "# most and least frequent words to filter\n",
    "for w in words:\n",
    "    if words[w] > MIN or words[w] < MAX:\n",
    "        words_filtered.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "courses_proc2 = {}\n",
    "\n",
    "for c in courses_proc:\n",
    "    courses_proc2[c] = [word for word in courses_proc[c] if word in words_filtered]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain which kinds of cleaning you implemented and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* make sure every courseId only appears once. If it appears more than once, append the two descriptions\n",
    "* Put all cheacters to lowercase, to avoid the same word being considered different. Additionally, all words in stopwords.pkl are in lowercase, so this ensures all words are removed correctly\n",
    "* Remove punctuation, for the same reason as above. Only the words are important, not which one is before a comma.\n",
    "* Remove stopwords, as these don't carry any information about the content of the document\n",
    "* filter most and least frequent words, ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the terms in the pre-processed description of the $9^{th}$ class in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10%', '10%', '10%', '2002', '2002', '2002', '2004', '2004', '2004', '2006', '2006', '2006', '2012', '2012', '2012', '3rd', '3rd', '3rd', '40%', '40%', '40%', '50%', '50%', '50%', 'abstract', 'abstract', 'abstract', 'abstractionexploit', 'abstractionexploit', 'abstractionexploit', 'activities', 'activities', 'activities', 'al', 'al', 'al', 'algorithmic', 'algorithmic', 'algorithmic', 'architecture', 'architecture', 'architecture', 'assessment', 'assessment', 'assessment', 'assistants', 'assistants', 'assistants', 'attending', 'attending', 'attending', 'automation', 'automation', 'automation', 'basic', 'basic', 'basic', 'bibliography', 'bibliography', 'bibliography', 'bibliothèque', 'bibliothèque', 'bibliothèque', 'building', 'building', 'building', 'challenges', 'challenges', 'challenges', 'chu', 'chu', 'chu', 'chusystem', 'chusystem', 'chusystem', 'coding', 'coding', 'coding', 'combinational', 'combinational', 'combinational', 'comments', 'comments', 'comments', 'completing', 'completing', 'completing', 'complex', 'complex', 'complex', 'components', 'components', 'components', 'computation', 'computation', 'computation', 'concepts', 'concepts', 'concepts', 'concepts', 'concepts', 'concepts', 'content', 'content', 'content', 'control', 'control', 'control', 'courses', 'courses', 'courses', 'courses', 'courses', 'courses', 'creation', 'creation', 'creation', 'cs171', 'cs171', 'cs171', 'dataflow', 'dataflow', 'dataflow', 'datapath', 'datapath', 'datapath', 'de', 'de', 'de', 'definition', 'definition', 'definition', 'delivered', 'delivered', 'delivered', 'describe', 'describe', 'describe', 'description', 'description', 'description', 'description', 'description', 'description', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'design', 'designcompare', 'designcompare', 'designcompare', 'designing', 'designing', 'designing', 'developing', 'developing', 'developing', 'df', 'df', 'df', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'digital', 'discreteevent', 'discreteevent', 'discreteevent', 'ed', 'ed', 'ed', 'eda', 'eda', 'eda', 'eda', 'eda', 'eda', 'ee334', 'ee334', 'ee334', 'ee397', 'ee397', 'ee397', 'efficiency', 'efficiency', 'efficiency', 'efficient', 'efficient', 'efficient', 'electronic', 'electronic', 'electronic', 'electronic', 'electronic', 'electronic', 'elements', 'elements', 'elements', 'elements', 'elements', 'elements', 'elsevier', 'elsevier', 'elsevier', 'embedded', 'embedded', 'embedded', 'embedded', 'embedded', 'embedded', 'en', 'en', 'en', 'end', 'end', 'end', 'environment', 'environment', 'environment', 'environment', 'environment', 'environment', 'environment', 'environment', 'environment', 'essential', 'essential', 'essential', 'examination', 'examination', 'examination', 'examination', 'examination', 'examination', 'exercises', 'exercises', 'exercises', 'exercises', 'exercises', 'exercises', 'exercises', 'exercises', 'exercises', 'expected', 'expected', 'expected', 'features', 'features', 'features', 'feedback', 'feedback', 'feedback', 'final', 'final', 'final', 'formalisms', 'formalisms', 'formalisms', 'formalismsuse', 'formalismsuse', 'formalismsuse', 'forum', 'forum', 'forum', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'functional', 'fundamental', 'fundamental', 'fundamental', 'grötker', 'grötker', 'grötker', 'grötker', 'grötker', 'grötker', 'guide', 'guide', 'guide', 'guide', 'guide', 'guide', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'hardware', 'homework', 'homework', 'homework', 'hours', 'hours', 'hours', 'httpmoodleepflchcourseviewphpid=40', 'httpmoodleepflchcourseviewphpid=40', 'httpmoodleepflchcourseviewphpid=40', 'httpwwwdouloscomknowhowvhdl_designers_guidehttpwwwdouloscomknowhowsysveriloghttpwwwdouloscomknowhowsystemc', 'httpwwwdouloscomknowhowvhdl_designers_guidehttpwwwdouloscomknowhowsysveriloghttpwwwdouloscomknowhowsystemc', 'httpwwwdouloscomknowhowvhdl_designers_guidehttpwwwdouloscomknowhowsysveriloghttpwwwdouloscomknowhowsystemc', 'important', 'important', 'important', 'including', 'including', 'including', 'individual', 'individual', 'individual', 'integrated', 'integrated', 'integrated', 'introduced', 'introduced', 'introduced', 'introduction', 'introduction', 'introduction', 'issues', 'issues', 'issues', 'jantsch', 'jantsch', 'jantsch', 'jantschrtl', 'jantschrtl', 'jantschrtl', 'kaufmann', 'kaufmann', 'kaufmann', 'keywords', 'keywords', 'keywords', 'lab', 'lab', 'lab', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'language', 'languages', 'languages', 'languages', 'languages', 'languages', 'languages', 'layered', 'layered', 'layered', 'learning', 'learning', 'learning', 'learning', 'learning', 'learning', 'learning', 'learning', 'learning', 'lectures', 'lectures', 'lectures', 'lectures', 'lectures', 'lectures', 'level', 'level', 'level', 'level', 'level', 'level', 'level', 'level', 'level', 'levels', 'levels', 'levels', 'link', 'link', 'link', 'logic', 'logic', 'logic', 'methodologies', 'methodologies', 'methodologies', 'methodologies', 'methodologies', 'methodologies', 'methodology', 'methodology', 'methodology', 'methods', 'methods', 'methods', 'methods', 'methods', 'methods', 'midterm', 'midterm', 'midterm', 'model', 'model', 'model', 'model', 'model', 'model', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'modeling', 'models', 'models', 'models', 'models', 'models', 'models', 'modelsconstruct', 'modelsconstruct', 'modelsconstruct', 'modern', 'modern', 'modern', 'moodle', 'moodle', 'moodle', 'moodle', 'moodle', 'moodle', 'morgan', 'morgan', 'morgan', 'notes', 'notes', 'notes', 'noteshandbook', 'noteshandbook', 'noteshandbook', 'notion', 'notion', 'notion', 'nutshell', 'nutshell', 'nutshell', 'office', 'office', 'office', 'open', 'open', 'open', 'osvvm', 'osvvm', 'osvvm', 'outcomes', 'outcomes', 'outcomes', 'page', 'page', 'page', 'plan', 'plan', 'plan', 'portability', 'portability', 'portability', 'pp', 'pp', 'pp', 'prerequisites', 'prerequisites', 'prerequisites', 'principles', 'principles', 'principles', 'problems', 'problems', 'problems', 'processing', 'processing', 'processing', 'proper', 'proper', 'proper', 'proper', 'proper', 'proper', 'quiz', 'quiz', 'quiz', 'recommended', 'recommended', 'recommended', 'required', 'required', 'required', 'required', 'required', 'required', 'resources', 'resources', 'resources', 'ressources', 'ressources', 'ressources', 'reusable', 'reusable', 'reusable', 'review', 'review', 'review', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'rtl', 'scalability', 'scalability', 'scalability', 'scalable', 'scalable', 'scalable', 'sequential', 'sequential', 'sequential', 'soc', 'soc', 'soc', \"soc's\", \"soc's\", \"soc's\", \"soc's\", \"soc's\", \"soc's\", 'socs', 'socs', 'socs', 'socs', 'socs', 'socs', 'source', 'source', 'source', 'spear', 'spear', 'spear', 'spearmodeling', 'spearmodeling', 'spearmodeling', 'springer', 'springer', 'springer', 'springer', 'springer', 'springer', 'start', 'start', 'start', 'stateoftheart', 'stateoftheart', 'stateoftheart', 'student', 'student', 'student', 'student', 'student', 'student', 'supervision', 'supervision', 'supervision', 'synthesis', 'synthesis', 'synthesis', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'system', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemc', 'systemonchip', 'systemonchip', 'systemonchip', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systems', 'systemsonchip', 'systemsonchip', 'systemsonchip', 'systemsonchip', 'systemsonchip', 'systemsonchip', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'systemverilog', 'tasks', 'tasks', 'tasks', 'teaching', 'teaching', 'teaching', 'techniquesdevelop', 'techniquesdevelop', 'techniquesdevelop', 'testbench', 'testbench', 'testbench', 'tlm', 'tlm', 'tlm', 'tool', 'tool', 'tool', 'tools', 'tools', 'tools', 'transactionlevel', 'transactionlevel', 'transactionlevel', 'tumbush', 'tumbush', 'tumbush', 'untimed', 'untimed', 'untimed', \"user's\", \"user's\", \"user's\", 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'verification', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdl', 'vhdlsystemverilogsystemc', 'vhdlsystemverilogsystemc', 'vhdlsystemverilogsystemc', 'websites', 'websites', 'websites', 'wileyinterscience', 'wileyinterscience', 'wileyinterscience', 'work', 'work', 'work']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(courses_proc2[courses[9]['courseId']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Construct an M×N term-document matrix X, where M is the number of terms and N is the number of documents. The matrix X should be sparse. You are not allowed to use libraries for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mapping from word to its index\n",
    "words_index = {}\n",
    "i = 0\n",
    "\n",
    "for w in words_filtered:\n",
    "    words_index[w] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mapping from courseId to its index\n",
    "courses_index = {}\n",
    "i = 0\n",
    "\n",
    "for w in courses_proc2:\n",
    "    courses_index[w] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = len(words_filtered)\n",
    "N = len(courses_proc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.ndarray((M, N))\n",
    "\n",
    "for c in courses_proc2:\n",
    "    for t in courses_proc2[c]:\n",
    "        X[words_index[t]][courses_index[c]] += 1\n",
    "        if courses_index[c]==0:\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the 15 terms in the description of the IX class with the highest TF-IDF scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain where the difference between the large scores and the small ones comes from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Search for \"markov chains\" and \"facebook\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "markov_index = words_index['markov']\n",
    "chains_index = words_index['chains']\n",
    "facebook_index = words_index['facebook']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the top five courses together with their similarity score for each query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you think of the results? Give your intuition on what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
