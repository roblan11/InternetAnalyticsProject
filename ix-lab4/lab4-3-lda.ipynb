{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 3: Latent Dirichlet allocation\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** K\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Kim Lan Phan Hoang\n",
    "* Robin Lang\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "from collections import defaultdict\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "import re\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')\n",
    "commonWords = [\"student\",\"students\",\"learning\",\"course\",\"courses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get RDD of courses\n",
    "data = sc.parallelize(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#transform documents into bags of word\n",
    "    #take only the description into account\n",
    "    #split depending on whitespace and punctuation\n",
    "    #only keep letter words\n",
    "    #lowercase words\n",
    "    #remove stopwords\n",
    "    #remove non-relevant words\n",
    "wordsInDocument = data\\\n",
    ".map(lambda x: x[\"description\"])\\\n",
    ".map(lambda x: re.split(\"[\\s\\.\\?\\!\\,\\;\\:\\-\\(\\)\\[\\]\\{\\}\\\"\\/]\", x))\\\n",
    ".map(lambda w: [x for x in w if x.isalpha()])\\\n",
    ".map(lambda w: [x.lower() for x in w])\\\n",
    ".map(lambda w: [x for x in w if (x not in stopwords) and (x not in commonWords)])\n",
    "\n",
    "\n",
    "#Group words in order to obtain a word list\n",
    "    #add a counter\n",
    "    #reducebykey to group words\n",
    "    #descending sort on number of recurrence\n",
    "mostReccurentWords = wordsInDocument\\\n",
    ".flatMap(lambda x: x)\\\n",
    ".map(lambda word: (word, 1))\\\n",
    ".reduceByKey(lambda x,y: x + y)\\\n",
    ".map(lambda x: (x[1], x[0]))\\\n",
    ".sortByKey(False)\n",
    "\n",
    "    \n",
    "# get all possible words and map them to an id\n",
    "wordsList = mostReccurentWords\\\n",
    ".map(lambda x: x[1])\\\n",
    ".zipWithIndex()\\\n",
    ".collectAsMap()\n",
    "\n",
    "distinctNbWords = len(wordsList)\n",
    "\n",
    "    \n",
    "# get a document and return a tuple (id , vector of word occurrencies )\n",
    "def documentToVector(d):\n",
    "    \n",
    "    wordOccurrencies = defaultdict(int) #initialize dict\n",
    "    for w in d[0]: \n",
    "        wordOccurrencies[wordsList[w]] += 1 # add one at word_id position\n",
    "            \n",
    "    wordOccurrencies = sorted(wordOccurrencies.items()) # in order to obtain a list for each element\n",
    "    wordOcc_0 = [x[0] for x in wordOccurrencies]\n",
    "    wordOcc_1 = [x[1] for x in wordOccurrencies]\n",
    "    \n",
    "    return (d[1], Vectors.sparse(distinctNbWords, wordOcc_0, wordOcc_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.8: Topics extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your pre-processed courses dataset, extract topics using LDA. Print k = 10 topics extracted using LDA and give them labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def displayTopicsWords(topic_indices):\n",
    "    for topic in topic_indices:\n",
    "        for w in topic[0]:\n",
    "            print(wordsList_helper[w])\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform indices into corresponding words\n",
    "wordsList_helper = mostReccurentWords.map(lambda x: x[1]).collect()\n",
    "\n",
    "# get right format to submit to lda\n",
    "    # zipWithIndex to obtain an id for the document\n",
    "    # get a vector of used words\n",
    "documents = wordsInDocument\\\n",
    ".zipWithIndex()\\\n",
    ".map(documentToVector)\\\n",
    ".map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "methods\n",
      "chemical\n",
      "chemistry\n",
      "processes\n",
      "properties\n",
      "equations\n",
      "concepts\n",
      "transfer\n",
      "heat\n",
      "basic\n",
      "\n",
      "\n",
      "project\n",
      "methods\n",
      "end\n",
      "evaluate\n",
      "content\n",
      "work\n",
      "outcomes\n",
      "report\n",
      "skills\n",
      "systems\n",
      "\n",
      "\n",
      "energy\n",
      "cell\n",
      "biology\n",
      "methods\n",
      "development\n",
      "teaching\n",
      "cells\n",
      "information\n",
      "content\n",
      "presentation\n",
      "\n",
      "\n",
      "project\n",
      "report\n",
      "scientific\n",
      "research\n",
      "based\n",
      "skills\n",
      "data\n",
      "plan\n",
      "methods\n",
      "analysis\n",
      "\n",
      "\n",
      "methods\n",
      "linear\n",
      "analysis\n",
      "data\n",
      "control\n",
      "theory\n",
      "algorithms\n",
      "models\n",
      "problems\n",
      "optimization\n",
      "\n",
      "\n",
      "models\n",
      "methods\n",
      "design\n",
      "data\n",
      "assessment\n",
      "work\n",
      "basic\n",
      "time\n",
      "tools\n",
      "lectures\n",
      "\n",
      "\n",
      "optical\n",
      "optics\n",
      "content\n",
      "methods\n",
      "applications\n",
      "electron\n",
      "microscopy\n",
      "imaging\n",
      "note\n",
      "introduction\n",
      "\n",
      "\n",
      "materials\n",
      "design\n",
      "methods\n",
      "quantum\n",
      "content\n",
      "mechanical\n",
      "assessment\n",
      "class\n",
      "keywords\n",
      "material\n",
      "\n",
      "\n",
      "systems\n",
      "design\n",
      "circuits\n",
      "modeling\n",
      "methods\n",
      "exercises\n",
      "signal\n",
      "power\n",
      "system\n",
      "content\n",
      "\n",
      "\n",
      "methods\n",
      "energy\n",
      "risk\n",
      "content\n",
      "space\n",
      "applications\n",
      "outcomes\n",
      "flow\n",
      "introduction\n",
      "end\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create lda model\n",
    "lda = LDA.train(documents, k = 10)\n",
    "\n",
    "# get topics\n",
    "topic_indices = lda.describeTopics(maxTermsPerTopic = 10) # 10 words to display\n",
    "displayTopicsWords(topic_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it compare with LSI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.9: Dirichlet hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analyse the effects of α and β."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From : https://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda we have the following definitions:\n",
    "\n",
    "docConcentration (alpha): Dirichlet parameter for prior over documents’ distributions over topics. Larger values encourage smoother inferred distributions.\n",
    "\n",
    "topicConcentration (beta): Dirichlet parameter for prior over topics’ distributions over terms (words). Larger values encourage smoother inferred distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix k = 10 and β = 1.01, and vary α. How does it impact the topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## FAIS UN GRAPH ROBIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix k = 10 and α = 6, and vary β. How does it impact the topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.10: EPFL's taught subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### List the subjects of EPFL’s classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the combination of k, α and β that gives most interpretable topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain why you chose these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the values of these hyperparameters that you used and your labels for the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.11: Wikipedia structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract the structure in terms of topics from the wikipedia-for-school dataset. Use your intuition about how many topics might be covered by the articles and how they are distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the values for k, α and β that you chose a priori and why you picked them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you convinced by the results? Give labels to the topics if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
