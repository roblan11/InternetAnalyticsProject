{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 3: Latent Dirichlet allocation\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** K\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* Kim Lan Phan Hoang\n",
    "* Robin Lang\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 3 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Donâ€™t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "from collections import defaultdict\n",
    "from pyspark.mllib.linalg import Vector, Vectors\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "import re\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')\n",
    "commonWords = [\"student\",\"students\",\"learning\",\"course\",\"courses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get RDD of courses\n",
    "data = sc.parallelize(courses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get a document and return a tuple (id , vector of word occurrencies )\n",
    "def documentToVector(d):\n",
    "    \n",
    "    wordOccurrencies = defaultdict(int) #initialize dict\n",
    "    for w in d[0]: \n",
    "        wordOccurrencies[wordsList[w]] += 1 # add one at word_id position\n",
    "            \n",
    "    wordOccurrencies = sorted(wordOccurrencies.items()) # in order to obtain a list for each element\n",
    "    wordOcc_0 = [x[0] for x in wordOccurrencies]\n",
    "    wordOcc_1 = [x[1] for x in wordOccurrencies]\n",
    "    \n",
    "    return (d[1], Vectors.sparse(distinctNbWords, wordOcc_0, wordOcc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Usage of pyspark LDA is highly inspired by the following: http://seanlane.net/blog/2016/PySpark_and_LDA\n",
    "\n",
    "#transform documents into bags of word\n",
    "    #take only the description into account\n",
    "    #split depending on whitespace and punctuation\n",
    "    #only keep letter words\n",
    "    #remove words whose length is smaller than 3\n",
    "    #lowercase words\n",
    "    #remove stopwords and  non-relevant words\n",
    "wordsInDocument = data.map(lambda x: x[\"description\"])\\\n",
    ".map(lambda x: re.split(\"[\\s\\.\\?\\!\\,\\;\\:\\-\\(\\)\\[\\]\\{\\}\\\"\\/]\", x))\\\n",
    ".map(lambda w: [x for x in w if x.isalpha()])\\\n",
    ".map(lambda w: [x for x in w if len(x)>3])\\\n",
    ".map(lambda w: [x.lower() for x in w])\\\n",
    ".map(lambda w: [x for x in w if (x not in stopwords) and (x not in commonWords)])\n",
    "\n",
    "\n",
    "#Group words in order to obtain a word list\n",
    "    #add a counter\n",
    "    #reducebykey to group words\n",
    "    #descending sort on word recurrences\n",
    "mostReccurentWords = wordsInDocument.flatMap(lambda x: x)\\\n",
    ".map(lambda word: (word, 1))\\\n",
    ".reduceByKey(lambda x,y: x + y)\\\n",
    ".map(lambda x: (x[1], x[0]))\\\n",
    ".sortByKey(False)\n",
    "\n",
    "    \n",
    "# get all possible words and map them to an id\n",
    "wordsList = mostReccurentWords.map(lambda x: x[1]).zipWithIndex().collectAsMap()\n",
    "distinctNbWords = len(wordsList)\n",
    "\n",
    "\n",
    "# get correct format to submit to lda\n",
    "    # zipWithIndex to obtain an id for the document\n",
    "    # get a vector of used words\n",
    "documents = wordsInDocument.zipWithIndex().map(documentToVector).map(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordsList_helper = mostReccurentWords.map(lambda x: x[1]).collect()\n",
    "\n",
    "def displayTopicsWords(lda_topics, alphaValues, betaValues):\n",
    "    for i in range(len(lda_topics)):\n",
    "        print(\"alpha = \",alphaValues[i],\"& beta =\",betaValues[i])\n",
    "        for j in range(10):\n",
    "            print(\"- Topic \",j+1,\": \",end=\"\")\n",
    "            for w in lda_topics[i][j][0]:\n",
    "                print(wordsList_helper[w],\"-\", end=\"\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.8: Topics extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using your pre-processed courses dataset, extract topics using LDA. Print k = 10 topics extracted using LDA and give them labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create lda model\n",
    "lda = LDA.train(documents, k = 10)\n",
    "\n",
    "# get topics\n",
    "topic_indices = lda.describeTopics(maxTermsPerTopic = 10) # 10 words to display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  default & beta = default\n",
      "- Topic  1 : methods -models -model -stochastic -theory -time -introduction -exam -financial -risk -\n",
      "- Topic  2 : methods -case -energy -management -content -work -assessment -outcomes -business -evaluate -\n",
      "- Topic  3 : methods -energy -equations -content -processes -transfer -applications -lecture -chemical -organic -\n",
      "- Topic  4 : optical -optics -microscopy -imaging -epfl -electron -engineering -methods -laser -light -\n",
      "- Topic  5 : methods -materials -content -assessment -paper -teaching -work -activities -theory -outcomes -\n",
      "- Topic  6 : methods -cell -protein -molecular -flow -content -chemical -research -biology -structure -\n",
      "- Topic  7 : design -methods -data -analysis -structures -mechanics -materials -content -work -engineering -\n",
      "- Topic  8 : project -plan -skills -methods -data -programming -scientific -systems -content -software -\n",
      "- Topic  9 : systems -design -system -modeling -methods -circuits -processing -digital -techniques -concepts -\n",
      "- Topic  10 : models -linear -analysis -methods -control -data -algorithms -basic -statistical -statistics -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayTopicsWords([topic_indices], [\"default\"],[\"default\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alpha =  default & beta = default\n",
    "- **financial risk** : methods -models -model -stochastic -theory -time -introduction -exam -financial -risk -\n",
    "- **energy management** : methods -case -energy -management -content -work -assessment -outcomes -business -evaluate -\n",
    "- **energy applications** : methods -energy -equations -content -processes -transfer -applications -lecture -chemical -organic -\n",
    "- **optical microscopy** : optical -optics -microscopy -imaging -epfl -electron -engineering -methods -laser -light -\n",
    "- **materials theory** : methods -materials -content -assessment -paper -teaching -work -activities -theory -outcomes -\n",
    "- **molecular research** : methods -cell -protein -molecular -flow -content -chemical -research -biology -structure -\n",
    "- **mechanics engineering** : design -methods -data -analysis -structures -mechanics -materials -content -work -engineering -\n",
    "- **software project** : project -plan -skills -methods -data -programming -scientific -systems -content -software -\n",
    "- **digital circuits modeling** : systems -design -system -modeling -methods -circuits -processing -digital -techniques -concepts\n",
    "- **linear algorithms** : models -linear -analysis -methods -control -data -algorithms -basic -statistical -statistics -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it compare with LSI?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In LSI, nearly every topic was related to either finances (containing words such as: finance, market, data, price, ...) or pharmacology (containing words such as: drug, disease, bioprocess, kinetics, ...). The only topic that was very different was based around projects, containing words as report, research and so on.\n",
    "\n",
    "In LDA the topics seem more varied, while finances, the project and biology in a broad sence are still present, there are other topics about energy, microscopy, software, circuits and similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.9: Dirichlet hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analyse the effects of Î± and Î²."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From : https://spark.apache.org/docs/latest/mllib-clustering.html#latent-dirichlet-allocation-lda we have the following definitions:\n",
    "\n",
    "docConcentration ($\\alpha$): Dirichlet parameter for prior over documentsâ€™ distributions over topics. Larger values encourage smoother inferred distributions.\n",
    "\n",
    "topicConcentration ($\\beta$): Dirichlet parameter for prior over topicsâ€™ distributions over terms (words). Larger values encourage smoother inferred distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix k = 10 and Î² = 1.01, and vary Î±. How does it impact the topics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "When the $\\alpha$ parameter is really high, the documents tend to be consisted of more topics (the probability the document is part of a topic tends to be equiprobable for all topics). We can see that when $\\alpha$ = 20, the topics retrieved are pretty similar. These topics are retrieved instead of others because \"methods\" is a top word. On the other hand, when $\\alpha$ = 1.01 is used, the top retrieved topics are the really specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def createLdaTopics(alphaValues, betaValues):\n",
    "    topics_indices = []\n",
    "    for i in range(len(alphaValues)):\n",
    "        lda = LDA.train(documents, k = 10,  docConcentration = alphaValues[i], topicConcentration = betaValues[i])\n",
    "        topics_indices.append(lda.describeTopics(maxTermsPerTopic = 10))\n",
    "    return topics_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create lda model\n",
    "alphaValues1 = [20., 10., 6., 3., 1.01]\n",
    "betaValues1 = [1.01, 1.01, 1.01, 1.01, 1.01]\n",
    "lda_topics1 = createLdaTopics(alphaValues1, betaValues1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  20.0 & beta = 1.01\n",
      "Topic  1 : methods -content -management -project -work -solid -energy -analysis -assessment -teaching -\n",
      "Topic  2 : methods -design -content -data -project -analysis -systems -assessment -basic -outcomes -\n",
      "Topic  3 : methods -data -content -analysis -report -project -skills -outcomes -assessment -prerequisites -\n",
      "Topic  4 : methods -content -analysis -data -models -outcomes -control -assessment -basic -prerequisites -\n",
      "Topic  5 : design -methods -systems -analysis -content -concepts -week -system -assessment -teaching -\n",
      "Topic  6 : methods -risk -content -theory -basic -model -probability -introduction -assessment -concepts -\n",
      "Topic  7 : methods -content -outcomes -concepts -energy -basic -design -prerequisites -assessment -analysis -\n",
      "Topic  8 : methods -architecture -content -project -research -work -design -assessment -semester -teaching -\n",
      "Topic  9 : methods -materials -systems -content -organic -devices -exercises -basic -analysis -assessment -\n",
      "Topic  10 : methods -systems -engineering -design -analysis -content -teaching -system -assessment -data -\n",
      "alpha =  10.0 & beta = 1.01\n",
      "Topic  1 : methods -content -research -innovation -assessment -project -evaluate -activities -social -skills -\n",
      "Topic  2 : models -methods -theory -probability -stochastic -linear -exercises -analysis -content -exam -\n",
      "Topic  3 : systems -control -methods -system -data -power -processing -design -signal -electronics -\n",
      "Topic  4 : design -methods -image -cell -digital -structures -week -basic -structural -analysis -\n",
      "Topic  5 : methods -equations -flow -numerical -models -molecular -analysis -basic -problems -protein -\n",
      "Topic  6 : data -methods -materials -risk -analysis -techniques -concepts -content -microscopy -basic -\n",
      "Topic  7 : methods -chemistry -content -systems -organic -concepts -outcomes -prerequisites -energy -properties -\n",
      "Topic  8 : methods -content -project -quantum -laser -work -semester -report -time -optical -\n",
      "Topic  9 : energy -methods -optical -content -design -principles -optics -devices -assessment -systems -\n",
      "Topic  10 : engineering -methods -project -teaching -systems -analysis -chemical -water -system -semester -\n",
      "alpha =  6.0 & beta = 1.01\n",
      "Topic  1 : methods -data -content -exercises -assessment -microscopy -skills -design -oral -basic -\n",
      "Topic  2 : chemistry -methods -chemical -organic -processes -applications -content -materials -reactions -modeling -\n",
      "Topic  3 : project -skills -plan -report -research -work -methods -data -scientific -based -\n",
      "Topic  4 : models -biology -methods -model -protein -paper -cell -molecular -content -exam -\n",
      "Topic  5 : methods -linear -analysis -theory -algorithms -processing -models -data -basic -optimization -\n",
      "Topic  6 : energy -materials -properties -power -physics -heat -phase -magnetic -transfer -equations -\n",
      "Topic  7 : design -methods -system -control -innovation -content -teaching -business -assessment -research -\n",
      "Topic  8 : systems -engineering -design -methods -exercises -content -lectures -expected -system -class -\n",
      "Topic  9 : methods -optical -quantum -risk -theory -laser -basic -optics -content -introduction -\n",
      "Topic  10 : design -methods -content -stability -week -digital -assessment -final -note -activities -\n",
      "alpha =  3.0 & beta = 1.01\n",
      "Topic  1 : methods -exam -assessment -work -theory -models -class -model -content -teaching -\n",
      "Topic  2 : chemical -chemistry -methods -processes -materials -magnetic -water -reactions -basic -content -\n",
      "Topic  3 : models -methods -analysis -linear -numerical -basic -concepts -exercises -equations -model -\n",
      "Topic  4 : methods -data -systems -algorithms -optimization -control -problems -analysis -system -design -\n",
      "Topic  5 : quantum -optical -materials -applications -content -methods -devices -mechanical -laser -design -\n",
      "Topic  6 : design -methods -teaching -development -work -group -research -project -content -skills -\n",
      "Topic  7 : energy -systems -design -methods -materials -concepts -heat -content -conversion -techniques -\n",
      "Topic  8 : methods -microscopy -optics -electron -content -imaging -optical -principles -mass -field -\n",
      "Topic  9 : scientific -biology -skills -information -project -methods -report -content -analysis -assessment -\n",
      "Topic  10 : project -semester -data -management -risk -engineering -research -systems -design -plan -\n",
      "alpha =  1.01 & beta = 1.01\n",
      "Topic  1 : design -project -methods -report -work -engineering -skills -semester -plan -week -\n",
      "Topic  2 : cell -biology -methods -molecular -biological -content -note -protein -cells -chemical -\n",
      "Topic  3 : design -methods -data -project -research -content -paper -work -presentation -assessment -\n",
      "Topic  4 : design -systems -methods -system -circuits -control -programming -content -processing -modeling -\n",
      "Topic  5 : optics -content -physics -applications -methods -optical -materials -properties -imaging -skills -\n",
      "Topic  6 : methods -quantum -materials -content -introduction -theory -image -physics -properties -magnetic -\n",
      "Topic  7 : linear -methods -models -basic -theory -analysis -probability -statistical -data -algebra -\n",
      "Topic  8 : data -methods -analysis -information -systems -management -class -project -concepts -content -\n",
      "Topic  9 : methods -numerical -models -analysis -project -time -equations -content -problems -introduction -\n",
      "Topic  10 : energy -methods -chemical -chemistry -processes -organic -heat -concepts -water -systems -\n"
     ]
    }
   ],
   "source": [
    "displayTopicsWords(lda_topics1, alphaValues1, betaValues1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix k = 10 and Î± = 6, and vary Î². How does it impact the topics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Larger is the parameter $\\beta$, more homogeneous become the topics. It is clearly the case when $\\beta$ is equal to 20, almost all topics contain the same words. It does not happen when $\\beta$ is small, like 1.01, the topics are more specific."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create lda model\n",
    "alphaValues2 = [6.,6.,6.,6.,6.]\n",
    "betaValues2 = [20., 10., 6., 3., 1.01]\n",
    "lda_topics2 = createLdaTopics(alphaValues2, betaValues2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  6.0  & beta =  20.0 : \n",
      "Topic  1 : methods -content -design -systems -analysis -end -assessment -outcomes -project -concepts -\n",
      "Topic  2 : methods -content -design -systems -analysis -end -assessment -data -outcomes -teaching -\n",
      "Topic  3 : methods -content -design -systems -analysis -end -assessment -outcomes -basic -teaching -\n",
      "Topic  4 : methods -content -design -analysis -end -systems -assessment -outcomes -basic -prerequisites -\n",
      "Topic  5 : methods -content -design -analysis -end -systems -assessment -outcomes -prerequisites -keywords -\n",
      "Topic  6 : methods -content -design -analysis -systems -end -assessment -outcomes -basic -data -\n",
      "Topic  7 : methods -content -systems -design -analysis -end -assessment -outcomes -basic -teaching -\n",
      "Topic  8 : methods -content -design -analysis -systems -end -assessment -outcomes -keywords -prerequisites -\n",
      "Topic  9 : methods -content -design -systems -analysis -end -assessment -outcomes -keywords -prerequisites -\n",
      "Topic  10 : methods -content -design -systems -analysis -end -assessment -outcomes -concepts -basic -\n",
      "\n",
      "alpha =  6.0  & beta =  10.0 : \n",
      "Topic  1 : methods -content -design -analysis -systems -end -assessment -outcomes -project -teaching -\n",
      "Topic  2 : methods -content -systems -design -analysis -basic -end -assessment -prerequisites -outcomes -\n",
      "Topic  3 : methods -content -design -analysis -systems -end -assessment -outcomes -basic -concepts -\n",
      "Topic  4 : methods -content -systems -design -analysis -end -assessment -basic -outcomes -prerequisites -\n",
      "Topic  5 : methods -content -design -analysis -systems -data -end -assessment -outcomes -project -\n",
      "Topic  6 : methods -content -systems -analysis -design -end -assessment -concepts -basic -teaching -\n",
      "Topic  7 : methods -content -design -systems -analysis -end -assessment -outcomes -teaching -project -\n",
      "Topic  8 : methods -design -content -systems -analysis -end -project -assessment -data -outcomes -\n",
      "Topic  9 : methods -content -design -end -systems -analysis -assessment -outcomes -basic -prerequisites -\n",
      "Topic  10 : methods -content -design -systems -analysis -end -assessment -outcomes -teaching -prerequisites -\n",
      "\n",
      "alpha =  6.0  & beta =  6.0 : \n",
      "Topic  1 : methods -project -content -design -analysis -data -end -assessment -work -skills -\n",
      "Topic  2 : methods -content -analysis -systems -design -end -basic -outcomes -prerequisites -assessment -\n",
      "Topic  3 : methods -content -energy -analysis -systems -end -assessment -outcomes -basic -prerequisites -\n",
      "Topic  4 : methods -content -systems -analysis -design -end -outcomes -assessment -concepts -basic -\n",
      "Topic  5 : methods -systems -design -content -analysis -basic -end -concepts -outcomes -assessment -\n",
      "Topic  6 : methods -content -design -project -end -assessment -work -analysis -data -teaching -\n",
      "Topic  7 : methods -content -systems -assessment -energy -end -basic -keywords -analysis -models -\n",
      "Topic  8 : methods -design -data -content -project -systems -analysis -end -assessment -outcomes -\n",
      "Topic  9 : methods -content -materials -design -assessment -basic -end -keywords -prerequisites -outcomes -\n",
      "Topic  10 : methods -systems -content -design -analysis -end -assessment -basic -teaching -keywords -\n",
      "\n",
      "alpha =  6.0  & beta =  3.0 : \n",
      "Topic  1 : methods -materials -content -design -end -project -analysis -assessment -work -outcomes -\n",
      "Topic  2 : methods -content -systems -design -end -assessment -keywords -basic -prerequisites -teaching -\n",
      "Topic  3 : methods -content -systems -end -assessment -outcomes -introduction -concepts -basic -teaching -\n",
      "Topic  4 : methods -content -design -analysis -end -outcomes -concepts -basic -prerequisites -teaching -\n",
      "Topic  5 : methods -theory -basic -content -analysis -design -assessment -ii -end -models -\n",
      "Topic  6 : methods -content -overview -assessment -design -keywords -end -teaching -research -analysis -\n",
      "Topic  7 : methods -design -models -systems -analysis -modeling -content -data -processing -end -\n",
      "Topic  8 : methods -chemistry -materials -content -chemical -energy -properties -basic -end -assessment -\n",
      "Topic  9 : systems -design -methods -system -data -project -energy -control -analysis -end -\n",
      "Topic  10 : methods -models -analysis -data -time -content -aspects -project -end -plan -\n",
      "\n",
      "alpha =  6.0  & beta =  1.01 : \n",
      "Topic  1 : energy -design -systems -methodology -methods -devices -circuits -control -term -end -\n",
      "Topic  2 : methods -data -basic -programming -content -concepts -information -theory -probability -management -\n",
      "Topic  3 : methods -process -content -teaching -research -presentation -overview -epfl -assessment -analysis -\n",
      "Topic  4 : methods -report -analysis -aspects -project -skills -plan -based -models -model -\n",
      "Topic  5 : methods -content -processes -models -analysis -basic -linear -exercises -lecture -prerequisites -\n",
      "Topic  6 : methods -modeling -magnetic -molecular -exercises -properties -content -physics -project -applications -\n",
      "Topic  7 : chemical -organic -methods -content -context -chemistry -state -assessment -properties -reactions -\n",
      "Topic  8 : methods -processing -linear -phase -analysis -basic -models -content -work -exercises -\n",
      "Topic  9 : methods -electron -content -ii -materials -keywords -energy -systems -introduction -prerequisites -\n",
      "Topic  10 : design -systems -optical -methods -data -project -optics -engineering -innovation -work -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "displayTopicsWords(lda_topics2, alphaValues2, betaValues2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.10: EPFL's taught subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### List the subjects of EPFLâ€™s classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the combination of k, Î± and Î² that gives most interpretable topics. Explain why you chose these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large values of $\\alpha, \\beta$ (> 1) tend towards a uniform posterior, which means the topics will be very similar.\n",
    "\n",
    "Small values of $\\alpha, \\beta$ (< 1) tend towards a small set of dominant topics, which means the topics will lose their relation and meaning.\n",
    "\n",
    "Therefore, we chose $\\alpha = \\beta = 1.01$\n",
    "\n",
    "Concerning the k parameter, EPFL has documents about lots of topics, so k needs to be high enough to create sufficiently enough topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  1.01 & beta = 1.01\n",
      "Topic  1 : design -data -systems -system -methods -programming -modeling -digital -tools -teaching -\n",
      "Topic  2 : magnetic -methods -cell -materials -content -drug -cells -note -molecular -introduction -\n",
      "Topic  3 : materials -chemical -chemistry -methods -properties -protein -structure -molecular -reaction -content -\n",
      "Topic  4 : methods -microscopy -electron -design -content -business -analysis -keywords -assessment -class -\n",
      "Topic  5 : methods -skills -transversal -work -content -concepts -outcomes -assessment -presentation -physical -\n",
      "Topic  6 : models -methods -theory -model -time -stochastic -financial -risk -finance -heat -\n",
      "Topic  7 : quantum -methods -content -theory -properties -basic -outcomes -systems -prerequisites -snow -\n",
      "Topic  8 : energy -project -methods -plan -skills -process -design -systems -conversion -outcomes -\n",
      "Topic  9 : methods -circuits -content -design -systems -noise -basic -devices -exercises -organic -\n",
      "Topic  10 : data -project -methods -paper -assessment -work -group -content -research -activities -\n"
     ]
    }
   ],
   "source": [
    "# create lda model\n",
    "lda3 = LDA.train(documents, k = 15, docConcentration = 1.01, topicConcentration = 1.01)\n",
    "\n",
    "# get topics\n",
    "lda_topics3 = lda3.describeTopics(maxTermsPerTopic = 10) # 10 words to display\n",
    "displayTopicsWords([lda_topics3], [1.01],[1.01])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the values of these hyperparameters that you used and your labels for the topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "k = 15 & $\\alpha$ =  1.01  & $\\beta$ =  1.01 : \n",
    "- **digital tools** : \n",
    "design -data -systems -system -methods -programming -modeling -digital -tools -teaching -\n",
    "- **magnetic cells** : \n",
    "magnetic -methods -cell -materials -content -drug -cells -note -molecular -introduction -\n",
    "- **chemical properties of protein** : \n",
    "materials -chemical -chemistry -methods -properties -protein -structure -molecular -reaction -content -\n",
    "- **electron analysis** : \n",
    " methods -microscopy -electron -design -content -business -analysis -keywords -assessment -class -\n",
    "- **transversal skills** : \n",
    " methods -skills -transversal -work -content -concepts -outcomes -assessment -presentation -physical -\n",
    "- **stochastic models in finance** : \n",
    "models -methods -theory -model -time -stochastic -financial -risk -finance -heat -\n",
    "- **quantum methods** : \n",
    "quantum -methods -content -theory -properties -basic -outcomes -systems -prerequisites -snow -\n",
    "- **energy systems** : \n",
    " energy -project -methods -plan -skills -process -design -systems -conversion -outcomes -\n",
    "- **circuits and systems noise** : \n",
    "methods -circuits -content -design -systems -noise -basic -devices -exercises -organic -\n",
    "- **project group** : \n",
    "data -project -methods -paper -assessment -work -group -content -research -activities -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.11: Wikipedia structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Extract the structure in terms of topics from the wikipedia-for-school dataset. Use your intuition about how many topics might be covered by the articles and how they are distributed. Report the values for k, Î± and Î² that you chose a priori and why you picked them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By following the same reasoning as for the EPFL dataset, we fixed the $\\alpha$ and $\\beta$ to their minimum 1.01.\n",
    "\n",
    "The variable k is also increased since wikipedia can contain a very large set of topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "wikipedia = sc.textFile(\"/ix/wikipedia-for-schools.txt\").map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Group words in order to obtain a word list\n",
    "#even if the wikipedia set is preprocessed, we need to clean it a bit more\n",
    "wikiProcessedWords = wikipedia.map(lambda x: x[\"tokens\"])\\\n",
    ".map(lambda w : [x for x in w if x.isalpha()])\\\n",
    ".map(lambda w : [x for x in w if len(x)>3])\n",
    "\n",
    "mostReccurentWords1 = processedWords.flatMap(lambda x: x)\\\n",
    ".map(lambda word: (word, 1))\\\n",
    ".reduceByKey(lambda x,y: x + y)\\\n",
    ".map(lambda x: (x[1], x[0]))\\\n",
    ".sortByKey(False)\n",
    "\n",
    "    \n",
    "# get all possible words and map them to an id\n",
    "wordsList1 = mostReccurentWords1.map(lambda x: x[1]).zipWithIndex().collectAsMap()\n",
    "distinctNbWords1 = len(wordsList1)\n",
    "\n",
    "\n",
    "# transform indices into corresponding words\n",
    "wordsList_helper1 = mostReccurentWords1.map(lambda x: x[1]).collect()\n",
    "\n",
    "\n",
    "# get correct format to submit to lda\n",
    "    # zipWithIndex to obtain an id for the document\n",
    "    # get a vector of used words\n",
    "documents1 = wikiProcessedWords.zipWithIndex().map(documentToVector1).map(list)\n",
    "\n",
    "    \n",
    "# get a document and return a tuple (id , vector of word occurrencies )\n",
    "def documentToVector1(d):\n",
    "    \n",
    "    wordOccurrencies = defaultdict(int) #initialize dict\n",
    "    for w in d[0]: \n",
    "        wordOccurrencies[wordsList1[w]] += 1 # add one at word_id position\n",
    "            \n",
    "    wordOccurrencies = sorted(wordOccurrencies.items()) # in order to obtain a list for each element\n",
    "    wordOcc_0 = [x[0] for x in wordOccurrencies]\n",
    "    wordOcc_1 = [x[1] for x in wordOccurrencies]\n",
    "    \n",
    "    return (d[1], Vectors.sparse(distinctNbWords1, wordOcc_0, wordOcc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayTopicsWords(lda_topics, alphaValues, betaValues):\n",
    "    for i in range(len(lda_topics)):\n",
    "        print(\"alpha = \",alphaValues[i],\"& beta =\",betaValues[i])\n",
    "        for j in range(10):\n",
    "            print(\"- Topic \",j+1,\": \",end=\"\")\n",
    "            for w in lda_topics[i][j][0]:\n",
    "                print(wordsList_helper1[w],\"-\", end=\"\")\n",
    "            print()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha =  1.01 & beta = 1.01\n",
      "- Topic  1 : time -world -united -years -american -states -city -british -people -century -\n",
      "- Topic  2 : city -time -government -years -world -states -united -century -state -american -\n",
      "- Topic  3 : time -years -american -world -united -city -states -number -century -made -\n",
      "- Topic  4 : time -world -years -states -united -number -century -city -called -government -\n",
      "- Topic  5 : american -time -years -world -united -city -states -century -government -british -\n",
      "- Topic  6 : american -time -years -city -world -united -states -century -french -made -\n",
      "- Topic  7 : time -years -world -century -united -number -states -city -called -american -\n",
      "- Topic  8 : american -time -united -years -world -british -states -government -city -century -\n",
      "- Topic  9 : error -time -world -years -american -city -states -century -united -unexpected -\n",
      "- Topic  10 : time -years -world -rajah -century -united -states -american -city -called -\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create lda model\n",
    "alphaValue_wiki = 1.01\n",
    "betaValue_wiki = 1.01\n",
    "k_wiki = 100\n",
    "\n",
    "lda_wiki = LDA.train(documents1, k = k_wiki, maxIterations=10, docConcentration = alphaValue_wiki, topicConcentration = betaValue_wiki)\n",
    "\n",
    "# get topics\n",
    "topic_indices_wiki = lda_wiki.describeTopics(maxTermsPerTopic = 10) # 10 words to display\n",
    "displayTopicsWords([topic_indices_wiki], [alphaValue_wiki], [betaValue_wiki])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are you convinced by the results? Give labels to the topics if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Even if we used smallest possible values for $\\alpha$ and $\\beta$, the results are quite bad, since the topics are very alike (they contain very similar words at their top) and giving them distinct labels would thus be difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
